Если вам просто поднять LLM дома в чатовом приложении, то есть следующие чат-приложения для разворачивания LLM:

## LMStudio  
https://lmstudio.ai/  
документация - https://lmstudio.ai/docs/basics

### Инструкция по установке (актуально для LMStudio версии 0.3.6)
Выбираем для своей платформы - Windows/Linux/MacOS  
После установки нажимаем - Get Your first LLM.  
Вначале предложат установить Llama 3.2 1B. Это маленькая и относительно бесполезная моделька, но можно установить в тестовых целях (особенно если у Вас нет видеокарты или видеокарта с < 4GB видеопамяти).  

Нажимаем **Download 1.32 GB** - будет скачана Llama 3.2 1B (конкретно https://huggingface.co/hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF)  

После загрузки нажимаем Start New Chat, появится окно чата, но модель пока не развернута на компьютере. Запускать модельку можно как на видеокарте (GPU) так и на процессоре (CPU - будет работать медленнее).  По-умолчанию выбирается **CPU**.  
Нажимаем сверху **Select a model to load** (в отдельной специальной строчке написано) и выбираем **Llama 3.2 1B Instruct** которая ранее была загружена.  
После того как модель будет развернута можно писать в чат - **Привет**, модель Вам ответит. Можно общаться. (но моделька довольно глупая, нужно бы найти что-то получше)

<img width="1003" alt="image" src="https://github.com/user-attachments/assets/ffba98c6-39d3-4808-a2ea-f4000721f10c" />  

Предлагаю запустить модельку на 2 миллиарда параметров **Gemma 2 2B**: будет загружена отсюда https://huggingface.co/lmstudio-community/gemma-2-2b-it-GGUF  
Для этого в строке поиска моделей сверху напишите **"gemma 2B"** после чего она появится в меню. Выберете ее и нажмите **Download**. Когда загрузится нажимаем **Use in New Chat** и общаемся.
