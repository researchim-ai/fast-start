Если вам просто поднять LLM дома в чатовом приложении, то есть следующие чат-приложения для разворачивания LLM:

## LMStudio  
https://lmstudio.ai/  
документация - https://lmstudio.ai/docs/basics

### Инструкция по установке (актуально для LMStudio версии 0.3.6)
Выбираем для своей платформы - Windows/Linux/MacOS  
После установки нажимаем - Get Your first LLM.  
Вначале предложат установить Llama 3.2 1B. Это маленькая и относительно бесполезная моделька, но можно установить в тестовых целях (особенно если у Вас нет видеокарты или видеокарта с < 4GB видеопамяти).  

Нажимаем **Download 1.32 GB** - будет скачана Llama 3.2 1B (конкретно https://huggingface.co/hugging-quants/Llama-3.2-1B-Instruct-Q8_0-GGUF)  

После загрузки нажимаем Start New Chat, появится окно чата, но модель пока не развернута на компьютере. Запускать модельку можно как на видеокарте (GPU) так и на процессоре (CPU - будет работать медленнее).  Если модель сможет быть загруженана GPU, то загрузится, если нет - то на CPU.  
Нажимаем сверху **Select a model to load** (в отдельной специальной строчке написано) и выбираем **Llama 3.2 1B Instruct** которая ранее была загружена.  
После того как модель будет развернута можно писать в чат - **Привет**, модель Вам ответит. Можно общаться. (но моделька довольно глупая, нужно бы найти что-то получше)

![image](https://github.com/user-attachments/assets/57f6227d-8a3f-4a43-817e-679d0ee04b40)
 
Предлагаю запустить модельку на 2 миллиарда параметров **Vikhr Gemma 2 2B**: будет загружена отсюда https://huggingface.co/Vikhrmodels/Vikhr-Gemma-2B-instruct-GGUF  
Это специально дотренированная на русский язык модель.  
Для этого в строке поиска моделей сверху напишите **vikhr gemma 2B** после чего она появится в меню. Выберете ее и нажмите **Download**. Когда загрузится нажимаем **Use in New Chat** и общаемся.

![image](https://github.com/user-attachments/assets/11c20096-99b2-41dc-98e7-0aa0cda47fae)

Можно выбрать разные квантированные версии - по-умолчанию предлагается Q4_0, но я бы рекомендовал версию **Q6_K**.
